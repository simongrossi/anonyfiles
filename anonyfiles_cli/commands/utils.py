# anonyfiles_cli/commands/utils.py

import typer
from pathlib import Path
from typing import Optional, List
from datetime import datetime

from ..ui.console_display import ConsoleDisplay
from ..utils.system_utils import detect_file_encoding # Import de la fonction
from ..exceptions import AnonyfilesError # Assurez-vous d'importer les exceptions n√©cessaires

app = typer.Typer(help="Commandes utilitaires pour Anonyfiles.")
console = ConsoleDisplay()

# D√©finition des codes de sortie pour Typer
class ExitCodes:
    SUCCESS = 0
    GENERAL_ERROR = 2
    CONFIG_ERROR = 3

@app.command(name="version", help="Affiche la version d'Anonyfiles.")
def show_version():
    """Affiche la version d'Anonyfiles."""
    console.console.print("üîß [bold]Anonyfiles CLI[/bold] - Version 1.2.0") # Mise √† jour de la version
    console.console.print("Outil d'anonymisation de fichiers bas√© sur spaCy")
    console.console.print("üìö Documentation: https://github.com/simongrossi/anonyfiles")

@app.command(name="list-entities", help="Liste les types d'entit√©s support√©es par spaCy.")
def list_entities():
    """Liste les types d'entit√©s support√©es par spaCy."""
    entities = {
        "PER": "Personnes (noms, pr√©noms)",
        "ORG": "Organisations (entreprises, institutions)",
        "LOC": "Lieux (villes, pays, adresses)",
        "MISC": "Divers (codes, r√©f√©rences)",
        "DATE": "Dates et heures",
        "EMAIL": "Adresses email",
        "PHONE": "Num√©ros de t√©l√©phone",
        "URL": "URLs et liens web",
        "IBAN": "Num√©ros IBAN",
        "ADDRESS": "Adresses compl√®tes"
    }
    
    console.console.print("üìã [bold]Types d'entit√©s support√©es par Anonyfiles CLI:[/bold]")
    for code, desc in entities.items():
        console.console.print(f"  ‚Ä¢ [cyan]{code}[/cyan]: {desc}")

@app.command(name="info", help="Affiche des informations d√©taill√©es sur un fichier.")
def file_info(
    input_file: Path = typer.Argument(..., help="Fichier √† analyser", exists=True, file_okay=True, dir_okay=False, readable=True)
):
    """Affiche des informations d√©taill√©es sur un fichier sans le traiter."""
    console.console.print(f"üìã [bold]Analyse de : {input_file.name}[/bold]")
    
    try:
        stat = input_file.stat()
        size_mb = stat.st_size / (1024 * 1024)
        
        console.console.print(f"üìÅ Taille : {stat.st_size:,} octets ({size_mb:.2f} MB)")
        console.console.print(f"üìÑ Extension : {input_file.suffix}")
        console.console.print(f"üìÖ Modifi√© : {datetime.fromtimestamp(stat.st_mtime)}")
        
        # Aper√ßu du contenu avec d√©tection d'encodage via le nouveau module
        encoding = detect_file_encoding(input_file)
        console.console.print(f"üî§ Encodage d√©tect√© : [yellow]{encoding}[/yellow]")

        content = ""
        try:
            with open(input_file, 'r', encoding=encoding) as f:
                content = f.read(1000)  # Premier Ko
                lines = content.count('\n') + 1
            
            console.console.print(f"üìù Lignes (approx.) : {lines}")
            
            preview = content[:200] + "..." if len(content) > 200 else content
            console.console.print(f"\nüìñ [dim]Aper√ßu :[/dim]\n{preview}")
            
        except UnicodeDecodeError:
            console.console.print("‚ö†Ô∏è Fichier binaire ou encodage non textuel/d√©tect√©. Impossible d'afficher l'aper√ßu textuel.", style="yellow")
        except Exception as e:
            console.console.print(f"‚ùå Erreur de lecture du contenu : {e}", style="red")

    except Exception as e:
        console.handle_error(e, "file_info_command")
        raise typer.Exit(code=ExitCodes.GENERAL_ERROR)


@app.command(name="benchmark", help="Teste les performances d'anonymisation sur un fichier donn√©.")
def run_benchmark(
    test_file: Path = typer.Argument(..., help="Fichier de test √† utiliser pour le benchmark.", exists=True, file_okay=True, dir_okay=False, readable=True),
    iterations: int = typer.Option(3, "--iterations", "-i", help="Nombre d'it√©rations pour le benchmark."),
    config: Optional[Path] = typer.Option(None, "--config", help="Fichier de configuration YAML √† tester pour le benchmark.", exists=True, file_okay=True, dir_okay=False, readable=True)
):
    """
    Teste les performances d'anonymisation d'Anonyfiles sur un fichier sp√©cifique.
    """
    from ..handlers.anonymize_handler import AnonymizeHandler # Import local pour √©viter les imports circulaires si ce handler d√©pend de benchmark
    from ..managers.config_manager import ConfigManager # Pour la config
    
    console.console.print(f"üöÄ [bold]Benchmark d'anonymisation[/bold]")
    console.console.print(f"üìÑ Fichier : [cyan]{test_file.name}[/cyan]")
    console.console.print(f"üîÑ It√©rations : [yellow]{iterations}[/yellow]")
    
    times = []
    
    # Pr√©parez un AnonymizeHandler pour le benchmark (peut-√™tre en mode silencieux)
    benchmark_handler = AnonymizeHandler(console) # Passe la console pour l'affichage interne
    
    for i in range(iterations):
        console.console.print(f"[{i+1}/{iterations}] Traitement de l'it√©ration...")
        
        start_time = time.time() # Importez 'time' si ce n'est pas d√©j√† fait
        
        try:
            # R√©cup√©rer la config effective (avec la possibilit√© d'une config pass√©e en param√®tre)
            effective_config = ConfigManager.get_effective_config(config)

            # Appel direct √† la logique d'anonymisation du handler en mode dry_run
            # On passe None pour les chemins de sortie car on ne veut pas √©crire de fichiers r√©els
            success = benchmark_handler.process(
                input_file=test_file,
                config_path=config, # Passe le chemin de config pour que le handler le g√®re
                output=None,
                log_entities=None,
                mapping_output=None,
                output_dir=Path("."), # Un r√©pertoire temporaire factice si n√©cessaire
                dry_run=True,  # IMPORTANT : Mode dry_run pour ne mesurer que le traitement
                csv_no_header=False, # Supposons un d√©faut pour le benchmark, ou ajouter une option
                has_header_opt=None, # Supposons un d√©faut pour le benchmark
                exclude_entities=None, # Laisser l'engine AnonyfilesEngine d√©cider
                custom_replacements_json=None, # Laisser l'engine AnonyfilesEngine d√©cider
                append_timestamp=False, # Pas pertinent en dry_run
                force=True # Pas pertinent en dry_run
            )
            
            end_time = time.time()
            duration = end_time - start_time
            times.append(duration)
            
            if success:
                console.console.print(f"  ‚è±Ô∏è [green]{duration:.2f}s[/green] - Traitement termin√©.")
            else:
                console.console.print(f"  ‚ùå Erreur pendant l'it√©ration, temps mesur√© : {duration:.2f}s", style="red")
            
        except Exception as e:
            console.console.print(f"  ‚ùå Erreur inattendue lors du benchmark : [red]{e}[/red]", style="red")
    
    if times:
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        console.console.print(f"\nüìä [bold]R√©sultats du Benchmark:[/bold]")
        console.console.print(f"‚è±Ô∏è Temps moyen : [cyan]{avg_time:.2f}s[/cyan]")
        console.console.print(f"üöÄ Plus rapide : [green]{min_time:.2f}s[/green]")
        console.console.print(f"üêå Plus lent : [red]{max_time:.2f}s[/red]")